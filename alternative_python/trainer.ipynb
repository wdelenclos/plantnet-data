{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import cv2\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load(\"saved_x.npy\")\n",
    "y = np.load(\"saved_y.npy\")\n",
    "cat = np.load(\"saved_cat.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(64, 3, padding='same', activation='relu', input_shape=(150, 150 ,3)),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(128, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(128, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(len(cat), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5807 samples, validate on 1025 samples\n",
      "Epoch 1/15\n",
      "5807/5807 [==============================] - 27s 5ms/sample - loss: 1.5636 - accuracy: 0.4350 - val_loss: 1.1969 - val_accuracy: 0.5600\n",
      "Epoch 2/15\n",
      "5807/5807 [==============================] - 23s 4ms/sample - loss: 0.9633 - accuracy: 0.6516 - val_loss: 0.9587 - val_accuracy: 0.6605\n",
      "Epoch 3/15\n",
      "5807/5807 [==============================] - 23s 4ms/sample - loss: 0.6068 - accuracy: 0.7815 - val_loss: 0.9864 - val_accuracy: 0.6761\n",
      "Epoch 4/15\n",
      "5807/5807 [==============================] - 23s 4ms/sample - loss: 0.3141 - accuracy: 0.8908 - val_loss: 1.2315 - val_accuracy: 0.6839\n",
      "Epoch 5/15\n",
      "5807/5807 [==============================] - 23s 4ms/sample - loss: 0.1783 - accuracy: 0.9420 - val_loss: 1.2487 - val_accuracy: 0.7015\n",
      "Epoch 6/15\n",
      "5807/5807 [==============================] - 23s 4ms/sample - loss: 0.0836 - accuracy: 0.9742 - val_loss: 1.6655 - val_accuracy: 0.6878\n",
      "Epoch 7/15\n",
      "5807/5807 [==============================] - 23s 4ms/sample - loss: 0.0750 - accuracy: 0.9812 - val_loss: 1.6693 - val_accuracy: 0.6849\n",
      "Epoch 8/15\n",
      "5807/5807 [==============================] - 23s 4ms/sample - loss: 0.0960 - accuracy: 0.9749 - val_loss: 1.4488 - val_accuracy: 0.7083\n",
      "Epoch 9/15\n",
      "5807/5807 [==============================] - 23s 4ms/sample - loss: 0.0392 - accuracy: 0.9900 - val_loss: 1.8292 - val_accuracy: 0.7083\n",
      "Epoch 10/15\n",
      "5807/5807 [==============================] - 23s 4ms/sample - loss: 0.0479 - accuracy: 0.9895 - val_loss: 1.6150 - val_accuracy: 0.7376\n",
      "Epoch 11/15\n",
      "5807/5807 [==============================] - 23s 4ms/sample - loss: 0.0575 - accuracy: 0.9848 - val_loss: 1.7231 - val_accuracy: 0.7161\n",
      "Epoch 12/15\n",
      "5807/5807 [==============================] - 23s 4ms/sample - loss: 0.0249 - accuracy: 0.9926 - val_loss: 1.9459 - val_accuracy: 0.7239\n",
      "Epoch 13/15\n",
      "5807/5807 [==============================] - 23s 4ms/sample - loss: 0.0453 - accuracy: 0.9898 - val_loss: 1.8146 - val_accuracy: 0.7132\n",
      "Epoch 14/15\n",
      "5807/5807 [==============================] - 23s 4ms/sample - loss: 0.0107 - accuracy: 0.9967 - val_loss: 1.9468 - val_accuracy: 0.7268\n",
      "Epoch 15/15\n",
      "5807/5807 [==============================] - 23s 4ms/sample - loss: 0.0073 - accuracy: 0.9985 - val_loss: 2.0659 - val_accuracy: 0.7054\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d2b00f5208>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y, batch_size=32, epochs=15, initial_epoch=0, shuffle=True, validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5807 samples, validate on 1025 samples\n",
      "Epoch 16/30\n",
      "5807/5807 [==============================] - 23s 4ms/sample - loss: 0.0061 - accuracy: 0.9983 - val_loss: 2.0152 - val_accuracy: 0.7337\n",
      "Epoch 17/30\n",
      "5807/5807 [==============================] - 23s 4ms/sample - loss: 0.0356 - accuracy: 0.9902 - val_loss: 2.0392 - val_accuracy: 0.7073\n",
      "Epoch 18/30\n",
      "5807/5807 [==============================] - 23s 4ms/sample - loss: 0.0937 - accuracy: 0.9761 - val_loss: 1.9058 - val_accuracy: 0.6976\n",
      "Epoch 19/30\n",
      "5807/5807 [==============================] - 23s 4ms/sample - loss: 0.0281 - accuracy: 0.9912 - val_loss: 2.0021 - val_accuracy: 0.7122\n",
      "Epoch 20/30\n",
      "5807/5807 [==============================] - 23s 4ms/sample - loss: 0.0031 - accuracy: 0.9993 - val_loss: 2.1029 - val_accuracy: 0.7288\n",
      "Epoch 21/30\n",
      "5807/5807 [==============================] - 23s 4ms/sample - loss: 0.0565 - accuracy: 0.9836 - val_loss: 2.2602 - val_accuracy: 0.7093\n",
      "Epoch 22/30\n",
      "5807/5807 [==============================] - 23s 4ms/sample - loss: 0.0783 - accuracy: 0.9835 - val_loss: 2.1772 - val_accuracy: 0.6751\n",
      "Epoch 23/30\n",
      "5807/5807 [==============================] - 23s 4ms/sample - loss: 0.0284 - accuracy: 0.9919 - val_loss: 2.0532 - val_accuracy: 0.6946\n",
      "Epoch 24/30\n",
      "5807/5807 [==============================] - 23s 4ms/sample - loss: 0.0168 - accuracy: 0.9954 - val_loss: 2.2360 - val_accuracy: 0.7180\n",
      "Epoch 25/30\n",
      "5807/5807 [==============================] - 23s 4ms/sample - loss: 0.0184 - accuracy: 0.9959 - val_loss: 2.3596 - val_accuracy: 0.7054\n",
      "Epoch 26/30\n",
      "5807/5807 [==============================] - 23s 4ms/sample - loss: 0.0062 - accuracy: 0.9983 - val_loss: 2.1662 - val_accuracy: 0.7083\n",
      "Epoch 27/30\n",
      "5807/5807 [==============================] - 23s 4ms/sample - loss: 0.0019 - accuracy: 0.9993 - val_loss: 2.4754 - val_accuracy: 0.7141\n",
      "Epoch 28/30\n",
      "5807/5807 [==============================] - 23s 4ms/sample - loss: 0.0330 - accuracy: 0.9928 - val_loss: 3.6201 - val_accuracy: 0.6585\n",
      "Epoch 29/30\n",
      "5807/5807 [==============================] - 23s 4ms/sample - loss: 0.0634 - accuracy: 0.9826 - val_loss: 2.0539 - val_accuracy: 0.7044\n",
      "Epoch 30/30\n",
      "5807/5807 [==============================] - 23s 4ms/sample - loss: 0.0129 - accuracy: 0.9964 - val_loss: 2.2351 - val_accuracy: 0.7102\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d2b0408208>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y, batch_size=32, epochs=30, initial_epoch=15, shuffle=True, validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5807 samples, validate on 1025 samples\n",
      "Epoch 31/31\n",
      "5807/5807 [==============================] - 23s 4ms/sample - loss: 0.0340 - accuracy: 0.9898 - val_loss: 2.3043 - val_accuracy: 0.6946\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x, y, batch_size=32, epochs=31, initial_epoch=30, shuffle=True, validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (31,) and (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-af0662c579b2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs_range\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Training Accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs_range\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Validation Accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'lower right'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2793\u001b[0m     return gca().plot(\n\u001b[0;32m   2794\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[1;32m-> 2795\u001b[1;33m         is not None else {}), **kwargs)\n\u001b[0m\u001b[0;32m   2796\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2797\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1664\u001b[0m         \"\"\"\n\u001b[0;32m   1665\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_alias_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1666\u001b[1;33m         \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1667\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1668\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    223\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m                 \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 225\u001b[1;33m             \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[1;34m(self, tup, kwargs)\u001b[0m\n\u001b[0;32m    389\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 391\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    392\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'plot'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m    268\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[1;32m--> 270\u001b[1;33m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[0;32m    271\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (31,) and (1,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = hist.history['accuracy']\n",
    "val_acc = hist.history['val_accuracy']\n",
    "\n",
    "loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "epochs_range = range(31)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
